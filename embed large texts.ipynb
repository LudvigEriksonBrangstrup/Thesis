{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68834b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index==0.9.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696a1fd",
   "metadata": {},
   "source": [
    "# hej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993b38c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (0) is close to chunk size (20). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (0) is close to chunk size (20). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (0) is close to chunk size (20). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (0) is close to chunk size (20). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (0) is close to chunk size (20). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "\n",
      "Category: bananas\n",
      "  doc1: 6 chunks with embedding dimension 384\n",
      "  doc2: 3 chunks with embedding dimension 384\n",
      "  doc3: 2 chunks with embedding dimension 384\n",
      "\n",
      "Category: apples\n",
      "  doc1: 6 chunks with embedding dimension 384\n",
      "  doc2: 3 chunks with embedding dimension 384\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "# Step 1: Use LlamaIndex chunkers for better text splitting\n",
    "def split_text_with_sentence_splitter(text, chunk_size=512, chunk_overlap=50):\n",
    "    \"\"\"\n",
    "    Splits text using LlamaIndex SentenceSplitter which respects sentence boundaries.\n",
    "    This creates more natural, semantically coherent chunks than simple word-based splitting.\n",
    "    \"\"\"\n",
    "    # Create a Document object (LlamaIndex's container for text)\n",
    "    document = Document(text=text)\n",
    "    \n",
    "    # Create a SentenceSplitter - this splits by sentences and then combines them into chunks\n",
    "    sentence_splitter = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        paragraph_separator=\"\\n\\n\",  # Adjust as needed for your text\n",
    "        separator=\" \"                # Separator used when combining sentences\n",
    "    )\n",
    "    \n",
    "    # Parse the document into nodes\n",
    "    nodes = sentence_splitter.get_nodes_from_documents([document])\n",
    "    \n",
    "    # Extract text from each node\n",
    "    chunks = [node.text for node in nodes]\n",
    "\n",
    "    # for i, chunk in enumerate(chunks):\n",
    "    #     print(f\"Chunk {i}: {chunk}\")  # Print first 50 characters of each chunk for debugging\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Step 2: Embed each chunk using SentenceTransformer\n",
    "class TextEmbedder:\n",
    "    def __init__(self, model_name=\"paraphrase-MiniLM-L6-v2\"):  # Using a more compatible model\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_text(self, chunks):\n",
    "        \"\"\"\n",
    "        Embeds a list of text chunks using SentenceTransformer.\n",
    "        \"\"\"\n",
    "        return self.model.encode(chunks)\n",
    "\n",
    "# Step 3: Group embeddings by category and document\n",
    "def process_texts_nested_dict(categories_dict, chunk_size=20, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Processes a nested dictionary of documents organized by categories,\n",
    "    splits them into chunks, embeds them, and preserves the hierarchy.\n",
    "    \n",
    "    Args:\n",
    "        categories_dict: Nested dictionary where:\n",
    "            - First level keys are categories (e.g., \"bananas\", \"apples\")\n",
    "            - Second level keys are document IDs\n",
    "            - Values contain 'doc_text' field\n",
    "        chunk_size: Size of each chunk\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        \n",
    "    Returns:\n",
    "        Nested dictionary with same structure but containing embeddings\n",
    "    \"\"\"\n",
    "    embedder = TextEmbedder()\n",
    "    grouped_embeddings = {}\n",
    "\n",
    "    for category, documents in categories_dict.items():\n",
    "        grouped_embeddings[category] = {}\n",
    "        \n",
    "        for doc_id, doc_data in documents.items():\n",
    "            text = doc_data[\"doc_text\"]\n",
    "            chunks = split_text_with_sentence_splitter(text, chunk_size, chunk_overlap)\n",
    "            if chunks:  # Make sure we have chunks before proceeding\n",
    "                embeddings = embedder.embed_text(chunks)\n",
    "                grouped_embeddings[category][doc_id] = np.array(embeddings)\n",
    "\n",
    "    return grouped_embeddings\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    categories_dict = {\n",
    "        \"bananas\": {\n",
    "            \"doc1\": {\n",
    "                \"doc_text\": \"This is the first example text. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks.\"\n",
    "            },\n",
    "            \"doc2\": {\n",
    "                \"doc_text\": \"Here is another text that will also be split and embedded. Here is another text that will also be split and embedded. Here is another text that will also be split and embedded.\"\n",
    "            },\n",
    "            \"doc3\": {\n",
    "                \"doc_text\": \"A third document with some content that will be processed into embeddings. A third document with some content that will be processed into embeddings.\"\n",
    "            }\n",
    "        },\n",
    "        \"apples\": {\n",
    "            \"doc1\": {\n",
    "                \"doc_text\": \"This is the first example text. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks. It is quite long and needs to be split into chunks.\"\n",
    "            },\n",
    "            \"doc2\": {\n",
    "                \"doc_text\": \"Here is another text that will also be split and embedded. Here is another text that will also be split and embedded. Here is another text that will also be split and embedded.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Process texts with LlamaIndex chunker\n",
    "    grouped_embeddings = process_texts_nested_dict(categories_dict)\n",
    "    \n",
    "    # Print information about the chunks\n",
    "    for category, documents in grouped_embeddings.items():\n",
    "        print(f\"\\nCategory: {category}\")\n",
    "        for doc_id, embeddings in documents.items():\n",
    "            print(f\"  {doc_id}: {len(embeddings)} chunks with embedding dimension {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09c4faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bananas': {'doc1': array([[-0.547143  ,  0.13099997, -0.29798925, ...,  0.3127594 ,\n",
       "           0.7349615 ,  0.58360195],\n",
       "         [-0.28905192,  0.11623957, -0.1416125 , ...,  0.17979482,\n",
       "           0.4187386 ,  0.14725946],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233]], dtype=float32),\n",
       "  'doc2': array([[-0.50558054,  0.26027247, -0.09289418, ...,  0.05310394,\n",
       "           0.35045525,  0.15219437],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148]], dtype=float32),\n",
       "  'doc3': array([[-7.42633283e-01, -6.01111129e-02, -4.73273009e-01,\n",
       "          -2.29590759e-01,  3.29517573e-01,  1.93717435e-01,\n",
       "          -9.10991579e-02, -6.96483612e-01,  4.13511395e-02,\n",
       "          -1.05482049e-01,  1.56857762e-02,  3.54383141e-01,\n",
       "           2.72643566e-01, -3.34605217e-01,  1.56243175e-01,\n",
       "          -2.03846157e-01,  4.36231017e-01,  6.14685893e-01,\n",
       "          -3.45672280e-01, -3.04801941e-01,  3.97480428e-01,\n",
       "          -5.76720499e-02,  1.80653241e-02, -6.63964450e-02,\n",
       "           5.00501513e-01,  1.13744840e-01, -6.18477106e-01,\n",
       "          -3.35835040e-01,  2.50484794e-01, -5.03387749e-01,\n",
       "           1.55241147e-01,  9.17206109e-02, -9.78812799e-02,\n",
       "          -1.12207226e-01,  3.39670271e-01,  1.37934506e-01,\n",
       "          -2.96159059e-01,  1.23458892e-01, -1.08654454e-01,\n",
       "           1.09523714e-01, -5.19536972e-01, -1.68189943e-01,\n",
       "          -4.97552454e-01,  2.85997689e-02, -2.28594407e-01,\n",
       "          -2.81681478e-01, -3.84017050e-01, -3.01293671e-01,\n",
       "           7.43926764e-02,  3.37030798e-01, -6.30577430e-02,\n",
       "          -1.75986394e-01, -6.55362785e-01,  3.84060711e-01,\n",
       "          -2.63966783e-03, -1.27541035e-01, -3.67893726e-02,\n",
       "           4.37370799e-02, -1.02959283e-01,  1.20723480e-02,\n",
       "           1.23140782e-01,  5.60647100e-02, -2.61724114e-01,\n",
       "           5.02153397e-01,  4.96003032e-01, -3.73124075e-03,\n",
       "          -2.09229484e-01, -6.39812127e-02, -4.58971441e-01,\n",
       "          -3.64750624e-02, -1.46689728e-01, -2.26242602e-01,\n",
       "          -4.49961305e-01,  1.51095107e-01,  2.51703709e-01,\n",
       "          -2.54595697e-01, -1.84799969e-01,  2.86446691e-01,\n",
       "          -1.79805443e-01, -3.95803094e-01,  1.18156157e-01,\n",
       "           2.13362187e-01, -2.67192900e-01,  4.47069377e-01,\n",
       "          -8.51729736e-02, -1.73030898e-01, -9.68908966e-02,\n",
       "          -3.24769914e-01, -3.67375910e-01,  1.08022757e-01,\n",
       "           4.84318614e-01, -5.20383060e-01,  6.28742516e-01,\n",
       "           2.96776388e-02,  1.20059587e-02,  2.02740401e-01,\n",
       "           9.06581730e-02,  3.28794599e-01,  5.75311840e-01,\n",
       "          -3.68629559e-03, -2.58563519e-01,  2.38599375e-01,\n",
       "           3.00809741e-01, -3.07423174e-01,  1.48759127e-01,\n",
       "          -2.85968721e-01,  3.46585333e-01, -2.29794800e-01,\n",
       "           1.01135164e-01, -2.88765907e-01, -2.61372745e-01,\n",
       "          -1.59155339e-01, -5.04506588e-01, -3.60220313e-01,\n",
       "          -1.26004159e-01,  2.62802064e-01,  7.43843019e-01,\n",
       "          -6.09981537e-01, -1.84991658e-02, -3.16329211e-01,\n",
       "           1.70030892e-01,  1.13498382e-01, -2.60351777e-01,\n",
       "           1.03504695e-02,  5.14937043e-01, -1.37293994e-01,\n",
       "           9.31603760e-02,  2.41017401e-01,  6.58119172e-02,\n",
       "          -3.26213211e-01,  7.98801705e-02,  1.63615629e-01,\n",
       "           7.23272502e-01,  3.82305272e-02,  1.06980644e-01,\n",
       "          -5.96164882e-01, -7.01810062e-01, -5.92485219e-02,\n",
       "           1.92793701e-02,  1.21155076e-01, -3.25543016e-01,\n",
       "           4.54581589e-01, -9.28799734e-02, -1.65497005e-01,\n",
       "          -9.13520530e-02,  5.49227238e-01, -5.96842110e-01,\n",
       "           2.64516801e-01,  2.49803603e-01, -9.55606401e-02,\n",
       "           7.27868602e-02, -4.65809405e-01, -2.97234684e-01,\n",
       "           6.16727412e-01,  4.47352454e-02, -1.78059280e-01,\n",
       "           7.27979839e-03,  8.40796158e-03,  1.75019160e-01,\n",
       "           2.12923974e-01,  2.20289320e-01,  8.31982493e-03,\n",
       "          -4.35513258e-01,  3.07889581e-01,  2.18756974e-01,\n",
       "          -5.33464514e-02,  5.88137060e-02,  2.40818158e-01,\n",
       "           4.70746011e-02,  1.11539930e-01,  2.66957611e-01,\n",
       "           9.77193415e-02, -3.43676396e-02,  1.62153482e-01,\n",
       "           5.41540861e-01,  2.57811069e-01,  1.39486194e-01,\n",
       "          -3.39871258e-01,  3.83450627e-01,  1.24746718e-01,\n",
       "           5.56989729e-01, -6.80031180e-02,  3.14962089e-01,\n",
       "           1.62662659e-02, -2.74436206e-01, -2.93610483e-01,\n",
       "           6.13243222e-01,  1.24681935e-01, -1.29857883e-01,\n",
       "           3.61554414e-01, -1.83018535e-01, -1.14323482e-01,\n",
       "           2.42811337e-01,  2.91351438e-01, -1.95108414e-01,\n",
       "           2.09345534e-01,  2.71575093e-01, -6.46097511e-02,\n",
       "          -6.42208755e-01, -1.01649456e-01,  2.22635061e-01,\n",
       "          -9.16128457e-02,  4.95550781e-01,  6.20636754e-02,\n",
       "          -3.58824372e-01, -1.61431462e-01, -6.44564703e-02,\n",
       "          -5.30838728e-01, -4.37602848e-01, -1.44759551e-01,\n",
       "           9.44874883e-02, -9.66879353e-03, -1.01920657e-01,\n",
       "           2.20811546e-01, -9.82305333e-02, -6.54328763e-02,\n",
       "          -4.17209119e-01, -2.41916239e-01, -2.74503380e-01,\n",
       "           1.45677298e-01, -6.07336499e-02, -2.17437953e-01,\n",
       "           3.94111067e-01, -3.27911615e-01, -2.52481461e-01,\n",
       "           9.04463604e-02, -3.17996949e-01,  2.54495025e-01,\n",
       "           1.12785734e-01,  1.91756487e-01,  1.48390494e-02,\n",
       "          -1.01048358e-01, -3.75426337e-02, -2.12155759e-01,\n",
       "          -2.58174896e-01, -3.41024846e-01, -4.87387367e-03,\n",
       "          -2.21774593e-01, -1.60380796e-01,  3.83232951e-01,\n",
       "           3.62842917e-01, -1.19569816e-01, -2.96903491e-01,\n",
       "          -9.15278718e-02, -1.72277063e-01,  2.17779186e-02,\n",
       "           4.43713553e-03,  6.29065990e-01,  1.35243237e-01,\n",
       "           1.51037574e-01, -1.87432811e-01, -3.19277644e-01,\n",
       "           7.87209198e-02,  1.01545647e-01, -1.62649885e-01,\n",
       "          -4.26680923e-01, -2.47340593e-02,  6.06546253e-02,\n",
       "          -9.52955484e-02,  1.15416527e-01,  3.45585823e-01,\n",
       "           2.36153945e-01, -1.98831901e-01,  2.68205941e-01,\n",
       "           3.76925290e-01,  4.23901007e-02, -1.71163008e-01,\n",
       "           2.87905097e-01, -5.95838428e-01,  2.10156277e-01,\n",
       "          -7.15310752e-01,  1.80354357e-01,  1.35833785e-01,\n",
       "           2.62674063e-01,  3.22386682e-01, -1.26567364e-01,\n",
       "           4.17260304e-02, -4.68999535e-01, -1.11090548e-01,\n",
       "           1.24552928e-01, -2.16303527e-01, -4.60994661e-01,\n",
       "           6.78609759e-02,  4.13396239e-01, -6.62773550e-01,\n",
       "          -7.34882206e-02,  2.44666636e-01, -3.77460152e-01,\n",
       "           5.76434255e-01, -2.88493365e-01, -1.85211629e-01,\n",
       "          -1.14824094e-01, -1.73795313e-01,  9.39948931e-02,\n",
       "           1.20921642e-01, -1.28821358e-01,  1.02412127e-01,\n",
       "           3.60370606e-01,  6.96473837e-01,  3.13986512e-03,\n",
       "          -1.60695717e-01, -3.21779656e-03,  3.76865603e-02,\n",
       "           3.15332383e-01,  3.43388677e-01, -1.66348889e-02,\n",
       "           2.83242106e-01,  3.17956686e-01,  2.30422631e-01,\n",
       "          -3.10326427e-01,  2.49143288e-01,  1.93161622e-01,\n",
       "          -3.91623050e-01,  6.26090467e-02,  4.31886967e-03,\n",
       "           6.99903488e-01,  2.31973857e-01,  6.69105411e-01,\n",
       "          -4.21450939e-03,  4.67240930e-01,  6.47448599e-02,\n",
       "           1.29230749e-02, -8.79065096e-02, -1.61656305e-01,\n",
       "          -1.66203305e-01,  2.92144150e-01, -2.42776468e-01,\n",
       "           1.93769202e-01, -1.76405028e-01, -3.89205486e-01,\n",
       "          -2.32330058e-02, -3.26826036e-01, -6.38189390e-02,\n",
       "          -3.48316282e-01, -1.16687261e-01, -2.14307964e-01,\n",
       "           4.78513464e-02, -2.74333566e-01, -8.18977728e-02,\n",
       "          -2.26110116e-01, -7.65831992e-02,  3.28465044e-01,\n",
       "          -2.21784279e-01,  2.84912139e-01,  1.25420261e-02,\n",
       "           3.28312367e-01, -1.20707460e-01,  5.56797683e-01,\n",
       "          -4.44607660e-02,  1.95668116e-02,  3.49840462e-01,\n",
       "           1.56789958e-01,  8.34418163e-02, -1.32206500e-01,\n",
       "           8.89602900e-02, -2.62238622e-01, -1.70994580e-01,\n",
       "          -4.62829880e-03, -5.54258347e-01,  5.68038225e-02,\n",
       "           1.21572308e-01, -3.13347459e-01, -2.27860242e-01,\n",
       "           2.21820489e-01,  5.10762513e-01, -1.17148690e-01,\n",
       "          -3.86266142e-01, -2.32539475e-01,  4.97843474e-01,\n",
       "           5.66241071e-02,  3.49690557e-01, -3.87619019e-01,\n",
       "           2.74114907e-01,  7.07031786e-01,  2.97630191e-01,\n",
       "          -3.12187463e-01,  3.45133662e-01, -1.22366520e-02,\n",
       "           4.68598247e-01,  2.76181877e-01, -4.15484428e-01,\n",
       "          -1.32135227e-01,  5.48190057e-01, -2.20519174e-02],\n",
       "         [-5.76340735e-01, -7.43514672e-02, -3.60657513e-01,\n",
       "          -9.31517407e-02,  2.39644274e-01,  2.01050445e-01,\n",
       "          -1.24355312e-02, -7.95276403e-01, -6.20940700e-02,\n",
       "          -1.24809124e-01,  1.05574474e-01,  1.59470856e-01,\n",
       "           2.25326419e-01, -2.32737884e-01,  1.77334383e-01,\n",
       "          -1.19054288e-01,  3.70594263e-01,  5.75457156e-01,\n",
       "          -3.89079660e-01, -3.73075992e-01,  2.99047202e-01,\n",
       "          -1.45823210e-01, -1.09457942e-02, -4.74711098e-02,\n",
       "           5.48317492e-01,  6.00830317e-02, -5.45131147e-01,\n",
       "          -4.34758127e-01,  3.14415097e-01, -2.78302252e-01,\n",
       "           1.36139289e-01,  3.73740271e-02, -1.25491902e-01,\n",
       "          -1.78353116e-01,  3.57023031e-01,  8.21469650e-02,\n",
       "          -3.89384985e-01,  1.82283834e-01, -1.00855544e-01,\n",
       "           1.45594463e-01, -4.70436364e-01, -1.94995850e-01,\n",
       "          -5.21484852e-01, -2.64634062e-02, -2.30839446e-01,\n",
       "          -3.74186575e-01, -3.14027518e-01, -3.14608395e-01,\n",
       "           1.03039116e-01,  2.85436213e-01,  1.64275728e-02,\n",
       "          -1.96028113e-01, -6.48355842e-01,  3.00066471e-01,\n",
       "          -6.67110085e-02, -9.30059999e-02, -8.19895789e-02,\n",
       "           4.68469225e-02,  2.09457316e-02,  7.92137980e-02,\n",
       "           8.08195025e-03, -1.60141829e-02, -1.36347935e-01,\n",
       "           4.53464568e-01,  2.55063117e-01, -1.76455230e-02,\n",
       "          -1.49240270e-01,  1.80660561e-02, -4.35881466e-01,\n",
       "          -4.68204804e-02, -6.17710575e-02, -2.42792919e-01,\n",
       "          -3.93792093e-01,  3.00071444e-02,  1.61071628e-01,\n",
       "          -2.60797024e-01, -3.42751946e-03,  3.39961261e-01,\n",
       "          -1.14496179e-01, -3.78095895e-01,  1.57011524e-01,\n",
       "           3.48689109e-01, -3.01460057e-01,  3.22329640e-01,\n",
       "          -6.85559362e-02, -1.95514262e-01, -2.11839482e-01,\n",
       "          -4.09788519e-01, -3.46170664e-01,  2.11004421e-01,\n",
       "           4.14582044e-01, -5.58548033e-01,  5.59316278e-01,\n",
       "           7.91465640e-02,  1.02279566e-01,  9.31993723e-02,\n",
       "          -1.97313186e-02,  4.05165672e-01,  6.24661744e-01,\n",
       "          -5.48258945e-02, -2.39620432e-01,  3.31069887e-01,\n",
       "           2.30546117e-01, -9.80192795e-02,  1.85472205e-01,\n",
       "          -1.49582833e-01,  2.69562215e-01, -3.25126827e-01,\n",
       "           9.83187556e-02, -2.12890491e-01, -2.30263665e-01,\n",
       "          -1.28959909e-01, -3.56550187e-01, -3.35476160e-01,\n",
       "          -1.17717057e-01,  3.36966783e-01,  7.10938573e-01,\n",
       "          -5.20871520e-01,  1.17903454e-02, -2.17600062e-01,\n",
       "           1.14779644e-01,  6.34009987e-02, -1.31113693e-01,\n",
       "          -9.77304801e-02,  5.40428519e-01, -1.45485446e-01,\n",
       "           9.34323296e-02,  5.82075007e-02,  5.45177832e-02,\n",
       "          -2.77254730e-01,  1.18252307e-01,  1.54366553e-01,\n",
       "           5.53001523e-01,  3.67881842e-02,  3.22081754e-03,\n",
       "          -5.42377412e-01, -6.48416758e-01, -7.26439804e-02,\n",
       "          -1.70073822e-01, -2.10689791e-02, -3.70755523e-01,\n",
       "           3.47667813e-01, -1.32682428e-01, -1.89043313e-01,\n",
       "          -4.82893102e-02,  4.04685199e-01, -5.69905818e-01,\n",
       "           2.11204380e-01,  1.18053831e-01, -1.11283874e-02,\n",
       "          -4.18567173e-02, -4.51487005e-01, -3.04150462e-01,\n",
       "           5.16151190e-01,  3.20751667e-02, -2.51068503e-01,\n",
       "           4.75262031e-02,  2.84130126e-02,  8.50804150e-02,\n",
       "           2.53802180e-01,  2.14112535e-01,  8.22842568e-02,\n",
       "          -3.86265337e-01,  2.93495744e-01,  1.37404114e-01,\n",
       "          -5.40573932e-02,  3.64071503e-02,  2.81243891e-01,\n",
       "           1.80030048e-01,  6.91971481e-02,  1.38001859e-01,\n",
       "           8.06927457e-02, -1.79195404e-03,  1.49710819e-01,\n",
       "           5.28308332e-01,  1.89148754e-01,  1.05179548e-01,\n",
       "          -3.49709779e-01,  4.34755385e-01,  1.18483134e-01,\n",
       "           6.29259288e-01, -4.38029841e-02,  3.40434790e-01,\n",
       "           4.71270941e-02, -1.64069965e-01, -2.57481903e-01,\n",
       "           4.56282675e-01,  1.73519850e-01, -1.33211806e-01,\n",
       "           3.70401114e-01, -8.70878175e-02, -1.16120182e-01,\n",
       "           2.68548727e-01,  3.64336282e-01, -2.57658422e-01,\n",
       "           1.37543872e-01,  1.74910009e-01, -1.23056944e-03,\n",
       "          -4.52276736e-01, -9.16572288e-02,  3.02616626e-01,\n",
       "          -2.36615151e-01,  4.26690370e-01,  9.67636406e-02,\n",
       "          -3.34151328e-01, -1.25412524e-01, -1.16598204e-01,\n",
       "          -5.38478732e-01, -4.67387706e-01, -1.66103140e-01,\n",
       "           1.34548560e-01, -1.53589565e-02,  8.41432586e-02,\n",
       "           2.25893274e-01, -1.47418365e-01, -1.43103739e-02,\n",
       "          -2.87740082e-01, -2.56268889e-01, -1.80713683e-01,\n",
       "           8.22343230e-02,  1.45978928e-02, -1.21176496e-01,\n",
       "           2.93558478e-01, -1.24820888e-01, -2.08588704e-01,\n",
       "           2.00138658e-01, -3.01870346e-01,  2.06568673e-01,\n",
       "          -7.21607497e-03,  1.46175027e-01, -1.87906340e-01,\n",
       "          -1.20080993e-01, -1.40565589e-01, -3.05339783e-01,\n",
       "          -2.32325152e-01, -2.79307634e-01, -4.61376719e-02,\n",
       "          -1.29405469e-01, -1.87318608e-01,  3.28951120e-01,\n",
       "           4.08056080e-01, -8.24415088e-02, -2.76222944e-01,\n",
       "          -4.53209765e-02, -1.39407888e-01,  4.61234041e-02,\n",
       "           6.18237890e-02,  4.51377928e-01,  9.89856571e-02,\n",
       "           1.55811116e-01, -1.20842345e-01, -3.05704802e-01,\n",
       "           9.28732082e-02,  1.47546045e-04, -1.60563111e-01,\n",
       "          -2.74081379e-01,  2.62966603e-01,  3.26288715e-02,\n",
       "          -4.40898724e-02,  7.95168430e-02,  2.47081846e-01,\n",
       "           2.65939772e-01, -1.90333217e-01,  2.49439016e-01,\n",
       "           2.11110607e-01,  3.84002142e-02, -2.28402585e-01,\n",
       "           3.05239439e-01, -5.59085071e-01,  2.89333075e-01,\n",
       "          -5.39624631e-01,  1.24626100e-01,  3.95777449e-02,\n",
       "           6.74570277e-02,  1.97118610e-01, -1.72660038e-01,\n",
       "           8.59976560e-03, -2.94570804e-01, -1.20525375e-01,\n",
       "           1.31490141e-01, -1.49892688e-01, -3.55103076e-01,\n",
       "           1.33191958e-01,  3.67852747e-01, -6.36411548e-01,\n",
       "          -1.70554761e-02,  2.63207674e-01, -3.55165482e-01,\n",
       "           5.29787421e-01, -2.59246290e-01, -2.28409827e-01,\n",
       "          -1.87608376e-01, -9.75958034e-02,  6.81530610e-02,\n",
       "           5.31721814e-03,  4.40594330e-02,  1.89333841e-01,\n",
       "           4.05957490e-01,  6.55410111e-01,  3.08849048e-02,\n",
       "          -2.83133566e-01, -7.76260570e-02,  1.22101590e-01,\n",
       "           1.94775999e-01,  4.25320596e-01, -1.20445505e-01,\n",
       "           2.44243398e-01,  2.28315443e-01,  9.67318192e-02,\n",
       "          -3.03281099e-01,  3.85010153e-01,  2.24269569e-01,\n",
       "          -3.31602961e-01, -4.91592847e-02,  7.73032606e-02,\n",
       "           5.41436732e-01,  2.71120608e-01,  4.61319059e-01,\n",
       "          -3.84698547e-02,  4.54040825e-01,  1.34845451e-01,\n",
       "          -6.58158436e-02, -7.94806033e-02, -1.65510371e-01,\n",
       "           7.00688874e-03,  2.25534126e-01, -2.33059898e-01,\n",
       "           2.75093347e-01, -1.47000313e-01, -4.70711380e-01,\n",
       "          -4.66392636e-02, -3.15454036e-01,  8.33907127e-02,\n",
       "          -2.71008521e-01, -6.76497370e-02, -1.58342481e-01,\n",
       "          -8.11886787e-03, -3.47353637e-01,  5.12445457e-02,\n",
       "          -1.85147718e-01, -9.32895914e-02,  2.18153134e-01,\n",
       "          -2.57464945e-01,  4.24667627e-01,  9.79810655e-02,\n",
       "           2.74945587e-01, -2.11944655e-02,  5.43226779e-01,\n",
       "          -3.03338561e-02,  8.42231736e-02,  2.63828456e-01,\n",
       "           1.54970899e-01,  2.51067374e-02, -8.16748440e-02,\n",
       "           3.19001265e-02, -2.67612040e-01, -2.35460088e-01,\n",
       "          -5.79256229e-02, -4.87567455e-01,  2.01183677e-01,\n",
       "           2.51195263e-02, -1.01086922e-01, -1.62994131e-01,\n",
       "           6.22592457e-02,  4.07026350e-01, -1.72532618e-01,\n",
       "          -3.45530421e-01, -1.90933287e-01,  4.39491987e-01,\n",
       "           1.03185475e-01,  3.42356205e-01, -3.88834208e-01,\n",
       "           1.95771784e-01,  7.09911168e-01,  2.67556071e-01,\n",
       "          -2.78501838e-01,  3.32487017e-01, -1.08949028e-01,\n",
       "           4.04820442e-01,  2.90554106e-01, -5.24557590e-01,\n",
       "          -1.04056381e-01,  4.03599501e-01, -1.24490216e-01]], dtype=float32)},\n",
       " 'apples': {'doc1': array([[-0.547143  ,  0.13099997, -0.29798925, ...,  0.3127594 ,\n",
       "           0.7349615 ,  0.58360195],\n",
       "         [-0.28905192,  0.11623957, -0.1416125 , ...,  0.17979482,\n",
       "           0.4187386 ,  0.14725946],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233]], dtype=float32),\n",
       "  'doc2': array([[-0.50558054,  0.26027247, -0.09289418, ...,  0.05310394,\n",
       "           0.35045525,  0.15219437],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148]], dtype=float32)}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bf807",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4536f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9538870",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_embedding.size(0)  # Replace 0 with the dimension you want to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "524cef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# Step 1: Define the GNN models\n",
    "class ChunkGNN(nn.Module):\n",
    "    \"\"\"GNN for creating document-level embeddings from chunks\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ChunkGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = global_mean_pool(x, batch)  # Pooling to get document-level embedding\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MasterGNN(nn.Module):\n",
    "    \"\"\"Graph neural network for aggregating document embeddings into a fixed-size master embedding\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MasterGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, document_embeddings):\n",
    "        \"\"\"\n",
    "        Create a fixed-size master embedding from document embeddings using a graph approach\n",
    "        \n",
    "        Args:\n",
    "            document_embeddings: Tensor of shape [num_documents, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "            Fixed-size master embedding regardless of number of input documents\n",
    "        \"\"\"\n",
    "        # Create a single batch for all documents (all in one graph)\n",
    "        batch = torch.zeros(document_embeddings.size(0), dtype=torch.long)\n",
    "        \n",
    "        # Create a fully connected graph between documents\n",
    "        if document_embeddings.size(0) > 1:\n",
    "            # Generate all pairs of indices for a fully connected graph\n",
    "            edge_index = torch.combinations(torch.arange(document_embeddings.size(0)), r=2).t()\n",
    "            # Make edges bidirectional\n",
    "            edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        else:\n",
    "            # Self-loop for a single document\n",
    "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "        \n",
    "        # Process through GNN\n",
    "        x = self.conv1(document_embeddings, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Global pooling to get fixed-size representation regardless of document count\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Step 2: Prepare data for chunk-level GNN\n",
    "def prepare_chunk_data(grouped_embeddings):\n",
    "    \"\"\"Convert grouped embeddings into PyTorch Geometric Data objects\"\"\"\n",
    "    data_list = []\n",
    "    for text_id, embeddings in grouped_embeddings.items():\n",
    "        # Create node features\n",
    "        x = torch.tensor(embeddings, dtype=torch.float)\n",
    "        \n",
    "        # Create a fully connected graph between chunks\n",
    "        num_nodes = x.size(0)\n",
    "        if num_nodes > 1:\n",
    "            # Create bidirectional edges for better message passing\n",
    "            edge_index = torch.combinations(torch.arange(num_nodes), r=2).t()\n",
    "            edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        else:\n",
    "            # Handle single node case with self-loop\n",
    "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "            \n",
    "        # Create a Data object\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        data_list.append(data)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Step 3: Process grouped embeddings through the GNNs\n",
    "def process_with_gnns(grouped_embeddings, chunk_gnn, master_gnn):\n",
    "    \"\"\"Process embeddings through GNNs to get a single fixed-size master embedding\"\"\"\n",
    "    # Prepare chunk-level data\n",
    "    data_list = prepare_chunk_data(grouped_embeddings)\n",
    "    loader = DataLoader(data_list, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Process each document through chunk-level GNN\n",
    "    document_embeddings = []\n",
    "    for data in loader:\n",
    "        document_embedding = chunk_gnn(data.x, data.edge_index, data.batch)\n",
    "        document_embeddings.append(document_embedding.squeeze(0))  # Remove batch dimension\n",
    "    \n",
    "    # Stack document embeddings\n",
    "    document_embeddings = torch.stack(document_embeddings)\n",
    "    \n",
    "    # Process through master GNN to get fixed-size embedding\n",
    "    master_embedding = master_gnn(document_embeddings)\n",
    "    \n",
    "    return master_embedding\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # For testing with different numbers of documents\n",
    "#     test_cases = [\n",
    "#         {\"text_0\": np.random.rand(5, 384)},  # 1 document\n",
    "#         {\"text_0\": np.random.rand(5, 384), \"text_1\": np.random.rand(3, 384)},  # 2 documents\n",
    "#         {\"text_0\": np.random.rand(5, 384), \"text_1\": np.random.rand(3, 384), \n",
    "#          \"text_2\": np.random.rand(4, 384), \"text_3\": np.random.rand(4, 384)}  # 4 documents\n",
    "#     ]\n",
    "    \n",
    "#     # Define fixed embedding dimensions\n",
    "#     embedding_dim = 384\n",
    "#     output_dim = 64\n",
    "    \n",
    "#     # Initialize models\n",
    "#     chunk_gnn = ChunkGNN(input_dim=embedding_dim, hidden_dim=128, output_dim=output_dim)\n",
    "#     master_gnn = MasterGNN(input_dim=output_dim, hidden_dim=32, output_dim=16)\n",
    "    \n",
    "#     # Test with different numbers of documents\n",
    "#     for i, grouped_embeddings in enumerate(test_cases):\n",
    "#         print(f\"\\nTest case {i+1}: {len(grouped_embeddings)} documents\")\n",
    "        \n",
    "#         # Process embeddings\n",
    "#         master_embedding = process_with_gnns(grouped_embeddings, chunk_gnn, master_gnn)\n",
    "        \n",
    "#         # Verify shape is consistent\n",
    "#         print(f\"Master embedding shape: {master_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5618ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hej\n",
      "hej\n",
      "Processing category: bananas with 3 documents\n",
      "Processing category: apples with 2 documents\n",
      "\n",
      "Category: bananas\n",
      "  Master embedding shape: torch.Size([1, 16])\n",
      "  First few values: [-0.16262401640415192, -0.03874002769589424, -0.07605313509702682, -0.04566062614321709, 0.05373515188694]\n",
      "\n",
      "Category: apples\n",
      "  Master embedding shape: torch.Size([1, 16])\n",
      "  First few values: [-0.1765163689851761, -0.02803163416683674, -0.07624045014381409, -0.034578364342451096, 0.04556804150342941]\n"
     ]
    }
   ],
   "source": [
    "def convert_nested_dict_to_simple_format(nested_embeddings):\n",
    "    \"\"\"\n",
    "    Converts a nested dictionary structure with categories to a dictionary where \n",
    "    each category maps to a simplified dictionary format compatible with process_with_gnns.\n",
    "    \n",
    "    Args:\n",
    "        nested_embeddings: Nested dictionary with categories as first level\n",
    "                          and documents as second level, containing numpy arrays\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary where each key is a category and each value is a simple dict\n",
    "        with keys like \"text_0\", \"text_1\", etc. mapping to numpy arrays\n",
    "    \"\"\"\n",
    "    converted_dict = {}\n",
    "    \n",
    "    for category, documents in nested_embeddings.items():\n",
    "        print(\"hej\")\n",
    "        # Create a simple dictionary for this category\n",
    "        simple_dict = {}\n",
    "        \n",
    "        # Convert document IDs to the text_N format\n",
    "        for i, (doc_id, embeddings) in enumerate(documents.items()):\n",
    "\n",
    "            simple_dict[f\"text_{i}\"] = embeddings\n",
    "        \n",
    "        # Store the simplified dictionary for this category\n",
    "        converted_dict[category] = simple_dict\n",
    "    \n",
    "    return converted_dict\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Convert the nested structure to the simplified format\n",
    "    converted_embeddings = convert_nested_dict_to_simple_format(grouped_embeddings)\n",
    "    \n",
    "    # Process each category with the existing process_with_gnns function\n",
    "    category_master_embeddings = {}\n",
    "    \n",
    "    for category, simple_dict in converted_embeddings.items():\n",
    "        print(f\"Processing category: {category} with {len(simple_dict)} documents\")\n",
    "        master_embedding = process_with_gnns(simple_dict, chunk_gnn, master_gnn)\n",
    "        category_master_embeddings[category] = master_embedding\n",
    "    \n",
    "    # Print results for each category\n",
    "    for category, embedding in category_master_embeddings.items():\n",
    "        print(f\"\\nCategory: {category}\")\n",
    "        print(f\"  Master embedding shape: {embedding.shape}\")\n",
    "        print(f\"  First few values: {embedding.flatten()[:5].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a84fdf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bananas': {'doc1': array([[-0.547143  ,  0.13099997, -0.29798925, ...,  0.3127594 ,\n",
       "           0.7349615 ,  0.58360195],\n",
       "         [-0.28905192,  0.11623957, -0.1416125 , ...,  0.17979482,\n",
       "           0.4187386 ,  0.14725946],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233]], dtype=float32),\n",
       "  'doc2': array([[-0.50558054,  0.26027247, -0.09289418, ...,  0.05310394,\n",
       "           0.35045525,  0.15219437],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148]], dtype=float32),\n",
       "  'doc3': array([[-7.42633283e-01, -6.01111129e-02, -4.73273009e-01,\n",
       "          -2.29590759e-01,  3.29517573e-01,  1.93717435e-01,\n",
       "          -9.10991579e-02, -6.96483612e-01,  4.13511395e-02,\n",
       "          -1.05482049e-01,  1.56857762e-02,  3.54383141e-01,\n",
       "           2.72643566e-01, -3.34605217e-01,  1.56243175e-01,\n",
       "          -2.03846157e-01,  4.36231017e-01,  6.14685893e-01,\n",
       "          -3.45672280e-01, -3.04801941e-01,  3.97480428e-01,\n",
       "          -5.76720499e-02,  1.80653241e-02, -6.63964450e-02,\n",
       "           5.00501513e-01,  1.13744840e-01, -6.18477106e-01,\n",
       "          -3.35835040e-01,  2.50484794e-01, -5.03387749e-01,\n",
       "           1.55241147e-01,  9.17206109e-02, -9.78812799e-02,\n",
       "          -1.12207226e-01,  3.39670271e-01,  1.37934506e-01,\n",
       "          -2.96159059e-01,  1.23458892e-01, -1.08654454e-01,\n",
       "           1.09523714e-01, -5.19536972e-01, -1.68189943e-01,\n",
       "          -4.97552454e-01,  2.85997689e-02, -2.28594407e-01,\n",
       "          -2.81681478e-01, -3.84017050e-01, -3.01293671e-01,\n",
       "           7.43926764e-02,  3.37030798e-01, -6.30577430e-02,\n",
       "          -1.75986394e-01, -6.55362785e-01,  3.84060711e-01,\n",
       "          -2.63966783e-03, -1.27541035e-01, -3.67893726e-02,\n",
       "           4.37370799e-02, -1.02959283e-01,  1.20723480e-02,\n",
       "           1.23140782e-01,  5.60647100e-02, -2.61724114e-01,\n",
       "           5.02153397e-01,  4.96003032e-01, -3.73124075e-03,\n",
       "          -2.09229484e-01, -6.39812127e-02, -4.58971441e-01,\n",
       "          -3.64750624e-02, -1.46689728e-01, -2.26242602e-01,\n",
       "          -4.49961305e-01,  1.51095107e-01,  2.51703709e-01,\n",
       "          -2.54595697e-01, -1.84799969e-01,  2.86446691e-01,\n",
       "          -1.79805443e-01, -3.95803094e-01,  1.18156157e-01,\n",
       "           2.13362187e-01, -2.67192900e-01,  4.47069377e-01,\n",
       "          -8.51729736e-02, -1.73030898e-01, -9.68908966e-02,\n",
       "          -3.24769914e-01, -3.67375910e-01,  1.08022757e-01,\n",
       "           4.84318614e-01, -5.20383060e-01,  6.28742516e-01,\n",
       "           2.96776388e-02,  1.20059587e-02,  2.02740401e-01,\n",
       "           9.06581730e-02,  3.28794599e-01,  5.75311840e-01,\n",
       "          -3.68629559e-03, -2.58563519e-01,  2.38599375e-01,\n",
       "           3.00809741e-01, -3.07423174e-01,  1.48759127e-01,\n",
       "          -2.85968721e-01,  3.46585333e-01, -2.29794800e-01,\n",
       "           1.01135164e-01, -2.88765907e-01, -2.61372745e-01,\n",
       "          -1.59155339e-01, -5.04506588e-01, -3.60220313e-01,\n",
       "          -1.26004159e-01,  2.62802064e-01,  7.43843019e-01,\n",
       "          -6.09981537e-01, -1.84991658e-02, -3.16329211e-01,\n",
       "           1.70030892e-01,  1.13498382e-01, -2.60351777e-01,\n",
       "           1.03504695e-02,  5.14937043e-01, -1.37293994e-01,\n",
       "           9.31603760e-02,  2.41017401e-01,  6.58119172e-02,\n",
       "          -3.26213211e-01,  7.98801705e-02,  1.63615629e-01,\n",
       "           7.23272502e-01,  3.82305272e-02,  1.06980644e-01,\n",
       "          -5.96164882e-01, -7.01810062e-01, -5.92485219e-02,\n",
       "           1.92793701e-02,  1.21155076e-01, -3.25543016e-01,\n",
       "           4.54581589e-01, -9.28799734e-02, -1.65497005e-01,\n",
       "          -9.13520530e-02,  5.49227238e-01, -5.96842110e-01,\n",
       "           2.64516801e-01,  2.49803603e-01, -9.55606401e-02,\n",
       "           7.27868602e-02, -4.65809405e-01, -2.97234684e-01,\n",
       "           6.16727412e-01,  4.47352454e-02, -1.78059280e-01,\n",
       "           7.27979839e-03,  8.40796158e-03,  1.75019160e-01,\n",
       "           2.12923974e-01,  2.20289320e-01,  8.31982493e-03,\n",
       "          -4.35513258e-01,  3.07889581e-01,  2.18756974e-01,\n",
       "          -5.33464514e-02,  5.88137060e-02,  2.40818158e-01,\n",
       "           4.70746011e-02,  1.11539930e-01,  2.66957611e-01,\n",
       "           9.77193415e-02, -3.43676396e-02,  1.62153482e-01,\n",
       "           5.41540861e-01,  2.57811069e-01,  1.39486194e-01,\n",
       "          -3.39871258e-01,  3.83450627e-01,  1.24746718e-01,\n",
       "           5.56989729e-01, -6.80031180e-02,  3.14962089e-01,\n",
       "           1.62662659e-02, -2.74436206e-01, -2.93610483e-01,\n",
       "           6.13243222e-01,  1.24681935e-01, -1.29857883e-01,\n",
       "           3.61554414e-01, -1.83018535e-01, -1.14323482e-01,\n",
       "           2.42811337e-01,  2.91351438e-01, -1.95108414e-01,\n",
       "           2.09345534e-01,  2.71575093e-01, -6.46097511e-02,\n",
       "          -6.42208755e-01, -1.01649456e-01,  2.22635061e-01,\n",
       "          -9.16128457e-02,  4.95550781e-01,  6.20636754e-02,\n",
       "          -3.58824372e-01, -1.61431462e-01, -6.44564703e-02,\n",
       "          -5.30838728e-01, -4.37602848e-01, -1.44759551e-01,\n",
       "           9.44874883e-02, -9.66879353e-03, -1.01920657e-01,\n",
       "           2.20811546e-01, -9.82305333e-02, -6.54328763e-02,\n",
       "          -4.17209119e-01, -2.41916239e-01, -2.74503380e-01,\n",
       "           1.45677298e-01, -6.07336499e-02, -2.17437953e-01,\n",
       "           3.94111067e-01, -3.27911615e-01, -2.52481461e-01,\n",
       "           9.04463604e-02, -3.17996949e-01,  2.54495025e-01,\n",
       "           1.12785734e-01,  1.91756487e-01,  1.48390494e-02,\n",
       "          -1.01048358e-01, -3.75426337e-02, -2.12155759e-01,\n",
       "          -2.58174896e-01, -3.41024846e-01, -4.87387367e-03,\n",
       "          -2.21774593e-01, -1.60380796e-01,  3.83232951e-01,\n",
       "           3.62842917e-01, -1.19569816e-01, -2.96903491e-01,\n",
       "          -9.15278718e-02, -1.72277063e-01,  2.17779186e-02,\n",
       "           4.43713553e-03,  6.29065990e-01,  1.35243237e-01,\n",
       "           1.51037574e-01, -1.87432811e-01, -3.19277644e-01,\n",
       "           7.87209198e-02,  1.01545647e-01, -1.62649885e-01,\n",
       "          -4.26680923e-01, -2.47340593e-02,  6.06546253e-02,\n",
       "          -9.52955484e-02,  1.15416527e-01,  3.45585823e-01,\n",
       "           2.36153945e-01, -1.98831901e-01,  2.68205941e-01,\n",
       "           3.76925290e-01,  4.23901007e-02, -1.71163008e-01,\n",
       "           2.87905097e-01, -5.95838428e-01,  2.10156277e-01,\n",
       "          -7.15310752e-01,  1.80354357e-01,  1.35833785e-01,\n",
       "           2.62674063e-01,  3.22386682e-01, -1.26567364e-01,\n",
       "           4.17260304e-02, -4.68999535e-01, -1.11090548e-01,\n",
       "           1.24552928e-01, -2.16303527e-01, -4.60994661e-01,\n",
       "           6.78609759e-02,  4.13396239e-01, -6.62773550e-01,\n",
       "          -7.34882206e-02,  2.44666636e-01, -3.77460152e-01,\n",
       "           5.76434255e-01, -2.88493365e-01, -1.85211629e-01,\n",
       "          -1.14824094e-01, -1.73795313e-01,  9.39948931e-02,\n",
       "           1.20921642e-01, -1.28821358e-01,  1.02412127e-01,\n",
       "           3.60370606e-01,  6.96473837e-01,  3.13986512e-03,\n",
       "          -1.60695717e-01, -3.21779656e-03,  3.76865603e-02,\n",
       "           3.15332383e-01,  3.43388677e-01, -1.66348889e-02,\n",
       "           2.83242106e-01,  3.17956686e-01,  2.30422631e-01,\n",
       "          -3.10326427e-01,  2.49143288e-01,  1.93161622e-01,\n",
       "          -3.91623050e-01,  6.26090467e-02,  4.31886967e-03,\n",
       "           6.99903488e-01,  2.31973857e-01,  6.69105411e-01,\n",
       "          -4.21450939e-03,  4.67240930e-01,  6.47448599e-02,\n",
       "           1.29230749e-02, -8.79065096e-02, -1.61656305e-01,\n",
       "          -1.66203305e-01,  2.92144150e-01, -2.42776468e-01,\n",
       "           1.93769202e-01, -1.76405028e-01, -3.89205486e-01,\n",
       "          -2.32330058e-02, -3.26826036e-01, -6.38189390e-02,\n",
       "          -3.48316282e-01, -1.16687261e-01, -2.14307964e-01,\n",
       "           4.78513464e-02, -2.74333566e-01, -8.18977728e-02,\n",
       "          -2.26110116e-01, -7.65831992e-02,  3.28465044e-01,\n",
       "          -2.21784279e-01,  2.84912139e-01,  1.25420261e-02,\n",
       "           3.28312367e-01, -1.20707460e-01,  5.56797683e-01,\n",
       "          -4.44607660e-02,  1.95668116e-02,  3.49840462e-01,\n",
       "           1.56789958e-01,  8.34418163e-02, -1.32206500e-01,\n",
       "           8.89602900e-02, -2.62238622e-01, -1.70994580e-01,\n",
       "          -4.62829880e-03, -5.54258347e-01,  5.68038225e-02,\n",
       "           1.21572308e-01, -3.13347459e-01, -2.27860242e-01,\n",
       "           2.21820489e-01,  5.10762513e-01, -1.17148690e-01,\n",
       "          -3.86266142e-01, -2.32539475e-01,  4.97843474e-01,\n",
       "           5.66241071e-02,  3.49690557e-01, -3.87619019e-01,\n",
       "           2.74114907e-01,  7.07031786e-01,  2.97630191e-01,\n",
       "          -3.12187463e-01,  3.45133662e-01, -1.22366520e-02,\n",
       "           4.68598247e-01,  2.76181877e-01, -4.15484428e-01,\n",
       "          -1.32135227e-01,  5.48190057e-01, -2.20519174e-02],\n",
       "         [-5.76340735e-01, -7.43514672e-02, -3.60657513e-01,\n",
       "          -9.31517407e-02,  2.39644274e-01,  2.01050445e-01,\n",
       "          -1.24355312e-02, -7.95276403e-01, -6.20940700e-02,\n",
       "          -1.24809124e-01,  1.05574474e-01,  1.59470856e-01,\n",
       "           2.25326419e-01, -2.32737884e-01,  1.77334383e-01,\n",
       "          -1.19054288e-01,  3.70594263e-01,  5.75457156e-01,\n",
       "          -3.89079660e-01, -3.73075992e-01,  2.99047202e-01,\n",
       "          -1.45823210e-01, -1.09457942e-02, -4.74711098e-02,\n",
       "           5.48317492e-01,  6.00830317e-02, -5.45131147e-01,\n",
       "          -4.34758127e-01,  3.14415097e-01, -2.78302252e-01,\n",
       "           1.36139289e-01,  3.73740271e-02, -1.25491902e-01,\n",
       "          -1.78353116e-01,  3.57023031e-01,  8.21469650e-02,\n",
       "          -3.89384985e-01,  1.82283834e-01, -1.00855544e-01,\n",
       "           1.45594463e-01, -4.70436364e-01, -1.94995850e-01,\n",
       "          -5.21484852e-01, -2.64634062e-02, -2.30839446e-01,\n",
       "          -3.74186575e-01, -3.14027518e-01, -3.14608395e-01,\n",
       "           1.03039116e-01,  2.85436213e-01,  1.64275728e-02,\n",
       "          -1.96028113e-01, -6.48355842e-01,  3.00066471e-01,\n",
       "          -6.67110085e-02, -9.30059999e-02, -8.19895789e-02,\n",
       "           4.68469225e-02,  2.09457316e-02,  7.92137980e-02,\n",
       "           8.08195025e-03, -1.60141829e-02, -1.36347935e-01,\n",
       "           4.53464568e-01,  2.55063117e-01, -1.76455230e-02,\n",
       "          -1.49240270e-01,  1.80660561e-02, -4.35881466e-01,\n",
       "          -4.68204804e-02, -6.17710575e-02, -2.42792919e-01,\n",
       "          -3.93792093e-01,  3.00071444e-02,  1.61071628e-01,\n",
       "          -2.60797024e-01, -3.42751946e-03,  3.39961261e-01,\n",
       "          -1.14496179e-01, -3.78095895e-01,  1.57011524e-01,\n",
       "           3.48689109e-01, -3.01460057e-01,  3.22329640e-01,\n",
       "          -6.85559362e-02, -1.95514262e-01, -2.11839482e-01,\n",
       "          -4.09788519e-01, -3.46170664e-01,  2.11004421e-01,\n",
       "           4.14582044e-01, -5.58548033e-01,  5.59316278e-01,\n",
       "           7.91465640e-02,  1.02279566e-01,  9.31993723e-02,\n",
       "          -1.97313186e-02,  4.05165672e-01,  6.24661744e-01,\n",
       "          -5.48258945e-02, -2.39620432e-01,  3.31069887e-01,\n",
       "           2.30546117e-01, -9.80192795e-02,  1.85472205e-01,\n",
       "          -1.49582833e-01,  2.69562215e-01, -3.25126827e-01,\n",
       "           9.83187556e-02, -2.12890491e-01, -2.30263665e-01,\n",
       "          -1.28959909e-01, -3.56550187e-01, -3.35476160e-01,\n",
       "          -1.17717057e-01,  3.36966783e-01,  7.10938573e-01,\n",
       "          -5.20871520e-01,  1.17903454e-02, -2.17600062e-01,\n",
       "           1.14779644e-01,  6.34009987e-02, -1.31113693e-01,\n",
       "          -9.77304801e-02,  5.40428519e-01, -1.45485446e-01,\n",
       "           9.34323296e-02,  5.82075007e-02,  5.45177832e-02,\n",
       "          -2.77254730e-01,  1.18252307e-01,  1.54366553e-01,\n",
       "           5.53001523e-01,  3.67881842e-02,  3.22081754e-03,\n",
       "          -5.42377412e-01, -6.48416758e-01, -7.26439804e-02,\n",
       "          -1.70073822e-01, -2.10689791e-02, -3.70755523e-01,\n",
       "           3.47667813e-01, -1.32682428e-01, -1.89043313e-01,\n",
       "          -4.82893102e-02,  4.04685199e-01, -5.69905818e-01,\n",
       "           2.11204380e-01,  1.18053831e-01, -1.11283874e-02,\n",
       "          -4.18567173e-02, -4.51487005e-01, -3.04150462e-01,\n",
       "           5.16151190e-01,  3.20751667e-02, -2.51068503e-01,\n",
       "           4.75262031e-02,  2.84130126e-02,  8.50804150e-02,\n",
       "           2.53802180e-01,  2.14112535e-01,  8.22842568e-02,\n",
       "          -3.86265337e-01,  2.93495744e-01,  1.37404114e-01,\n",
       "          -5.40573932e-02,  3.64071503e-02,  2.81243891e-01,\n",
       "           1.80030048e-01,  6.91971481e-02,  1.38001859e-01,\n",
       "           8.06927457e-02, -1.79195404e-03,  1.49710819e-01,\n",
       "           5.28308332e-01,  1.89148754e-01,  1.05179548e-01,\n",
       "          -3.49709779e-01,  4.34755385e-01,  1.18483134e-01,\n",
       "           6.29259288e-01, -4.38029841e-02,  3.40434790e-01,\n",
       "           4.71270941e-02, -1.64069965e-01, -2.57481903e-01,\n",
       "           4.56282675e-01,  1.73519850e-01, -1.33211806e-01,\n",
       "           3.70401114e-01, -8.70878175e-02, -1.16120182e-01,\n",
       "           2.68548727e-01,  3.64336282e-01, -2.57658422e-01,\n",
       "           1.37543872e-01,  1.74910009e-01, -1.23056944e-03,\n",
       "          -4.52276736e-01, -9.16572288e-02,  3.02616626e-01,\n",
       "          -2.36615151e-01,  4.26690370e-01,  9.67636406e-02,\n",
       "          -3.34151328e-01, -1.25412524e-01, -1.16598204e-01,\n",
       "          -5.38478732e-01, -4.67387706e-01, -1.66103140e-01,\n",
       "           1.34548560e-01, -1.53589565e-02,  8.41432586e-02,\n",
       "           2.25893274e-01, -1.47418365e-01, -1.43103739e-02,\n",
       "          -2.87740082e-01, -2.56268889e-01, -1.80713683e-01,\n",
       "           8.22343230e-02,  1.45978928e-02, -1.21176496e-01,\n",
       "           2.93558478e-01, -1.24820888e-01, -2.08588704e-01,\n",
       "           2.00138658e-01, -3.01870346e-01,  2.06568673e-01,\n",
       "          -7.21607497e-03,  1.46175027e-01, -1.87906340e-01,\n",
       "          -1.20080993e-01, -1.40565589e-01, -3.05339783e-01,\n",
       "          -2.32325152e-01, -2.79307634e-01, -4.61376719e-02,\n",
       "          -1.29405469e-01, -1.87318608e-01,  3.28951120e-01,\n",
       "           4.08056080e-01, -8.24415088e-02, -2.76222944e-01,\n",
       "          -4.53209765e-02, -1.39407888e-01,  4.61234041e-02,\n",
       "           6.18237890e-02,  4.51377928e-01,  9.89856571e-02,\n",
       "           1.55811116e-01, -1.20842345e-01, -3.05704802e-01,\n",
       "           9.28732082e-02,  1.47546045e-04, -1.60563111e-01,\n",
       "          -2.74081379e-01,  2.62966603e-01,  3.26288715e-02,\n",
       "          -4.40898724e-02,  7.95168430e-02,  2.47081846e-01,\n",
       "           2.65939772e-01, -1.90333217e-01,  2.49439016e-01,\n",
       "           2.11110607e-01,  3.84002142e-02, -2.28402585e-01,\n",
       "           3.05239439e-01, -5.59085071e-01,  2.89333075e-01,\n",
       "          -5.39624631e-01,  1.24626100e-01,  3.95777449e-02,\n",
       "           6.74570277e-02,  1.97118610e-01, -1.72660038e-01,\n",
       "           8.59976560e-03, -2.94570804e-01, -1.20525375e-01,\n",
       "           1.31490141e-01, -1.49892688e-01, -3.55103076e-01,\n",
       "           1.33191958e-01,  3.67852747e-01, -6.36411548e-01,\n",
       "          -1.70554761e-02,  2.63207674e-01, -3.55165482e-01,\n",
       "           5.29787421e-01, -2.59246290e-01, -2.28409827e-01,\n",
       "          -1.87608376e-01, -9.75958034e-02,  6.81530610e-02,\n",
       "           5.31721814e-03,  4.40594330e-02,  1.89333841e-01,\n",
       "           4.05957490e-01,  6.55410111e-01,  3.08849048e-02,\n",
       "          -2.83133566e-01, -7.76260570e-02,  1.22101590e-01,\n",
       "           1.94775999e-01,  4.25320596e-01, -1.20445505e-01,\n",
       "           2.44243398e-01,  2.28315443e-01,  9.67318192e-02,\n",
       "          -3.03281099e-01,  3.85010153e-01,  2.24269569e-01,\n",
       "          -3.31602961e-01, -4.91592847e-02,  7.73032606e-02,\n",
       "           5.41436732e-01,  2.71120608e-01,  4.61319059e-01,\n",
       "          -3.84698547e-02,  4.54040825e-01,  1.34845451e-01,\n",
       "          -6.58158436e-02, -7.94806033e-02, -1.65510371e-01,\n",
       "           7.00688874e-03,  2.25534126e-01, -2.33059898e-01,\n",
       "           2.75093347e-01, -1.47000313e-01, -4.70711380e-01,\n",
       "          -4.66392636e-02, -3.15454036e-01,  8.33907127e-02,\n",
       "          -2.71008521e-01, -6.76497370e-02, -1.58342481e-01,\n",
       "          -8.11886787e-03, -3.47353637e-01,  5.12445457e-02,\n",
       "          -1.85147718e-01, -9.32895914e-02,  2.18153134e-01,\n",
       "          -2.57464945e-01,  4.24667627e-01,  9.79810655e-02,\n",
       "           2.74945587e-01, -2.11944655e-02,  5.43226779e-01,\n",
       "          -3.03338561e-02,  8.42231736e-02,  2.63828456e-01,\n",
       "           1.54970899e-01,  2.51067374e-02, -8.16748440e-02,\n",
       "           3.19001265e-02, -2.67612040e-01, -2.35460088e-01,\n",
       "          -5.79256229e-02, -4.87567455e-01,  2.01183677e-01,\n",
       "           2.51195263e-02, -1.01086922e-01, -1.62994131e-01,\n",
       "           6.22592457e-02,  4.07026350e-01, -1.72532618e-01,\n",
       "          -3.45530421e-01, -1.90933287e-01,  4.39491987e-01,\n",
       "           1.03185475e-01,  3.42356205e-01, -3.88834208e-01,\n",
       "           1.95771784e-01,  7.09911168e-01,  2.67556071e-01,\n",
       "          -2.78501838e-01,  3.32487017e-01, -1.08949028e-01,\n",
       "           4.04820442e-01,  2.90554106e-01, -5.24557590e-01,\n",
       "          -1.04056381e-01,  4.03599501e-01, -1.24490216e-01]], dtype=float32)},\n",
       " 'apples': {'doc1': array([[-0.547143  ,  0.13099997, -0.29798925, ...,  0.3127594 ,\n",
       "           0.7349615 ,  0.58360195],\n",
       "         [-0.28905192,  0.11623957, -0.1416125 , ...,  0.17979482,\n",
       "           0.4187386 ,  0.14725946],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233],\n",
       "         [-0.07625767, -0.05811209, -0.08879285, ..., -0.20441213,\n",
       "           0.17478123, -0.22232233]], dtype=float32),\n",
       "  'doc2': array([[-0.50558054,  0.26027247, -0.09289418, ...,  0.05310394,\n",
       "           0.35045525,  0.15219437],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148],\n",
       "         [-0.39704907,  0.25346982,  0.10586175, ..., -0.00925015,\n",
       "           0.19879848,  0.12182148]], dtype=float32)}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81bca95",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Load all datasets\n",
    "embeddings_dir = os.path.join(os.getcwd(), 'WOS_embeddings')\n",
    "train_embeddings = np.load(os.path.join(embeddings_dir, 'train_embeddings.npy'))\n",
    "val_embeddings = np.load(os.path.join(embeddings_dir, 'val_embeddings.npy'))\n",
    "test_embeddings = np.load(os.path.join(embeddings_dir, 'test_embeddings.npy'))\n",
    "\n",
    "# Load labels for all sets\n",
    "train_labels_l1 = np.load(os.path.join(embeddings_dir, 'train_labels_l1.npy'))\n",
    "train_labels_l2 = np.load(os.path.join(embeddings_dir, 'train_labels_l2.npy'))\n",
    "\n",
    "val_labels_l1 = np.load(os.path.join(embeddings_dir, 'val_labels_l1.npy'))\n",
    "val_labels_l2 = np.load(os.path.join(embeddings_dir, 'val_labels_l2.npy'))\n",
    "\n",
    "test_labels_l1 = np.load(os.path.join(embeddings_dir, 'test_labels_l1.npy'))\n",
    "test_labels_l2 = np.load(os.path.join(embeddings_dir, 'test_labels_l2.npy'))\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Training embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"Validation embeddings shape: {val_embeddings.shape}\")\n",
    "print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
    "\n",
    "# Get number of categories at each level\n",
    "num_classes_l1 = len(np.unique(train_labels_l1))\n",
    "num_classes_l2 = len(np.unique(train_labels_l2))\n",
    "\n",
    "print(f\"Number of L1 categories: {num_classes_l1}\")\n",
    "print(f\"Number of L2 categories: {num_classes_l2}\")\n",
    "\n",
    "# 1. Create the hierarchical category graph with just 2 levels\n",
    "def create_category_hierarchy_graph():\n",
    "    \"\"\"\n",
    "    Create a graph representing the hierarchical structure of categories:\n",
    "    Root -> L1 categories -> L2 categories\n",
    "    \"\"\"\n",
    "    # Get unique combinations of categories at different levels\n",
    "    unique_combinations = {}\n",
    "    \n",
    "    # Process training set to map hierarchical relationships\n",
    "    for l1, l2 in zip(train_labels_l1, train_labels_l2):\n",
    "        if l1 not in unique_combinations:\n",
    "            unique_combinations[l1] = set()\n",
    "        unique_combinations[l1].add(l2)\n",
    "    \n",
    "    # Create mappings and node features\n",
    "    node_to_idx = {}\n",
    "    idx_to_node = {}\n",
    "    node_features = []\n",
    "    \n",
    "    # Root node (index 0)\n",
    "    node_idx = 0\n",
    "    node_to_idx[('root', 0)] = node_idx\n",
    "    idx_to_node[node_idx] = ('root', 0)\n",
    "    node_features.append([1.0, 0.0])  # One-hot for root level\n",
    "    node_idx += 1\n",
    "    \n",
    "    # L1 categories\n",
    "    for l1 in sorted(unique_combinations.keys()):\n",
    "        node_to_idx[('l1', l1)] = node_idx\n",
    "        idx_to_node[node_idx] = ('l1', l1)\n",
    "        node_features.append([0.0, 1.0])  # One-hot for L1\n",
    "        node_idx += 1\n",
    "    \n",
    "    # L2 categories (final categories)\n",
    "    for l1 in sorted(unique_combinations.keys()):\n",
    "        for l2 in sorted(unique_combinations[l1]):\n",
    "            node_to_idx[('l2', l2)] = node_idx\n",
    "            idx_to_node[node_idx] = ('l2', l2)\n",
    "            node_features.append([0.0, 0.0])  # Special encoding for L2\n",
    "            node_idx += 1\n",
    "    \n",
    "    # Create edges (root -> L1 -> L2)\n",
    "    edges = []\n",
    "    \n",
    "    # Root to L1 connections\n",
    "    for l1 in sorted(unique_combinations.keys()):\n",
    "        edges.append((node_to_idx[('root', 0)], node_to_idx[('l1', l1)]))\n",
    "        edges.append((node_to_idx[('l1', l1)], node_to_idx[('root', 0)]))  # Bidirectional\n",
    "    \n",
    "    # L1 to L2 connections\n",
    "    for l1 in sorted(unique_combinations.keys()):\n",
    "        for l2 in sorted(unique_combinations[l1]):\n",
    "            edges.append((node_to_idx[('l1', l1)], node_to_idx[('l2', l2)]))\n",
    "            edges.append((node_to_idx[('l2', l2)], node_to_idx[('l1', l1)]))  # Bidirectional\n",
    "    \n",
    "    # Convert to PyTorch Geometric format\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    return edge_index, node_features, node_to_idx, idx_to_node\n",
    "\n",
    "# 2. Create the graph and initialize mappings\n",
    "cat_edge_index, cat_node_features, node_to_idx, idx_to_node = create_category_hierarchy_graph()\n",
    "num_cat_nodes = cat_node_features.shape[0]\n",
    "\n",
    "print(f\"Category hierarchy graph created with {num_cat_nodes} nodes and {cat_edge_index.shape[1]} edges\")\n",
    "\n",
    "# 3. Define the GNN model for category hierarchy embedding\n",
    "class CategoryGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(CategoryGNN, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=4)\n",
    "        self.conv2 = GATConv(hidden_channels * 4, out_channels, heads=1)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 4. Define the classifier that combines category and text embeddings\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, text_dim, cat_embedding_dim, hidden_dim, num_classes_l1, num_classes_l2):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.category_gnn = CategoryGNN(cat_node_features.shape[1], 32, cat_embedding_dim)\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        combined_dim = text_dim + cat_embedding_dim\n",
    "        \n",
    "        # Shared layers\n",
    "        self.fc1 = nn.Linear(combined_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        \n",
    "        # Output heads for hierarchical classification\n",
    "        self.out_l1 = nn.Linear(hidden_dim // 2, num_classes_l1)\n",
    "        self.out_l2 = nn.Linear(hidden_dim // 2, num_classes_l2)\n",
    "        \n",
    "        # Store category node mappings\n",
    "        self.node_to_idx = node_to_idx\n",
    "        \n",
    "    def forward(self, text_embeddings, edge_index, node_features):\n",
    "        # Get category embeddings from GNN\n",
    "        cat_embeddings = self.category_gnn(node_features, edge_index)\n",
    "        \n",
    "        # For each text sample, combine with a learnable category embedding\n",
    "        batch_size = text_embeddings.shape[0]\n",
    "        combined_features = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # In a real implementation, we would use actual category info here\n",
    "            # For now, we'll use a zero vector as a placeholder\n",
    "            dummy_embedding = torch.zeros(cat_embeddings.shape[1], device=text_embeddings.device)\n",
    "            combined = torch.cat([text_embeddings[i], dummy_embedding])\n",
    "            combined_features.append(combined)\n",
    "            \n",
    "        combined_features = torch.stack(combined_features)\n",
    "        \n",
    "        # Shared layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "        # Output heads\n",
    "        out_l1 = self.out_l1(x)\n",
    "        out_l2 = self.out_l2(x)\n",
    "        \n",
    "        return out_l1, out_l2, cat_embeddings\n",
    "\n",
    "# 5. Set up training and evaluation utilities\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "cat_edge_index = cat_edge_index.to(device)\n",
    "cat_node_features = cat_node_features.to(device)\n",
    "\n",
    "train_x = torch.tensor(train_embeddings, dtype=torch.float).to(device)\n",
    "train_y_l1 = torch.tensor(train_labels_l1, dtype=torch.long).to(device)\n",
    "train_y_l2 = torch.tensor(train_labels_l2, dtype=torch.long).to(device)\n",
    "\n",
    "val_x = torch.tensor(val_embeddings, dtype=torch.float).to(device)\n",
    "val_y_l1 = torch.tensor(val_labels_l1, dtype=torch.long).to(device)\n",
    "val_y_l2 = torch.tensor(val_labels_l2, dtype=torch.long).to(device)\n",
    "\n",
    "test_x = torch.tensor(test_embeddings, dtype=torch.float).to(device)\n",
    "test_y_l1 = torch.tensor(test_labels_l1, dtype=torch.long).to(device)\n",
    "test_y_l2 = torch.tensor(test_labels_l2, dtype=torch.long).to(device)\n",
    "\n",
    "# Initialize model\n",
    "text_dim = train_embeddings.shape[1]\n",
    "cat_embedding_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "model = HierarchicalClassifier(\n",
    "    text_dim=text_dim, \n",
    "    cat_embedding_dim=cat_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes_l1=num_classes_l1,\n",
    "    num_classes_l2=num_classes_l2\n",
    ").to(device)\n",
    "\n",
    "# 6. Set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# 7. Training function\n",
    "def train_epoch(model, optimizer, batch_x, batch_y_l1, batch_y_l2):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    out_l1, out_l2, cat_embeddings = model(batch_x, cat_edge_index, cat_node_features)\n",
    "    \n",
    "    # Calculate loss for each level\n",
    "    loss_l1 = F.cross_entropy(out_l1, batch_y_l1)\n",
    "    loss_l2 = F.cross_entropy(out_l2, batch_y_l2)\n",
    "    \n",
    "    # Combined loss with weights\n",
    "    total_loss = 0.4 * loss_l1 + 0.6 * loss_l2\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss.item(), loss_l1.item(), loss_l2.item()\n",
    "\n",
    "# 8. Evaluation function\n",
    "def evaluate(model, x, y_l1, y_l2):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        out_l1, out_l2, _ = model(x, cat_edge_index, cat_node_features)\n",
    "        \n",
    "        # Get predictions\n",
    "        pred_l1 = out_l1.argmax(dim=1).cpu().numpy()\n",
    "        pred_l2 = out_l2.argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Convert labels to numpy for evaluation\n",
    "        true_l1 = y_l1.cpu().numpy()\n",
    "        true_l2 = y_l2.cpu().numpy()\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        acc_l1 = accuracy_score(true_l1, pred_l1)\n",
    "        acc_l2 = accuracy_score(true_l2, pred_l2)\n",
    "        \n",
    "    return acc_l1, acc_l2, pred_l1, pred_l2\n",
    "\n",
    "# 9. Training loop\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "print(\"\\nTraining the hierarchical GNN model...\")\n",
    "for epoch in range(epochs):\n",
    "    # Train on training data\n",
    "    total_loss, loss_l1, loss_l2 = train_epoch(\n",
    "        model, optimizer, train_x, train_y_l1, train_y_l2\n",
    "    )\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    if (epoch + 1) % 15 == 0 or epoch == 0:\n",
    "        # Evaluate on validation data\n",
    "        val_acc_l1, val_acc_l2, _, _ = evaluate(model, val_x, val_y_l1, val_y_l2)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, \"\n",
    "              f\"Val Acc L1: {val_acc_l1:.4f}, L2: {val_acc_l2:.4f}\")\n",
    "        \n",
    "        # Update learning rate based on validation performance\n",
    "        scheduler.step(total_loss)\n",
    "\n",
    "# 10. Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(embeddings_dir, 'hierarchical_gnn_loss.png'))\n",
    "plt.show()\n",
    "\n",
    "# 11. Final evaluation on test set\n",
    "test_acc_l1, test_acc_l2, pred_l1, pred_l2 = evaluate(model, test_x, test_y_l1, test_y_l2)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Level 1 Accuracy: {test_acc_l1:.4f}\")\n",
    "print(f\"Level 2 Accuracy: {test_acc_l2:.4f}\")\n",
    "\n",
    "# 12. Save the model\n",
    "torch.save(model.state_dict(), os.path.join(embeddings_dir, 'hierarchical_gnn_model.pt'))\n",
    "print(f\"Model saved to {os.path.join(embeddings_dir, 'hierarchical_gnn_model.pt')}\")\n",
    "\n",
    "# 13. Detailed classification reports\n",
    "print(\"\\nClassification Report (Level 1):\")\n",
    "print(classification_report(test_y_l1.cpu().numpy(), pred_l1))\n",
    "\n",
    "print(\"\\nClassification Report (Level 2):\")\n",
    "print(classification_report(test_y_l2.cpu().numpy(), pred_l2))\n",
    "\n",
    "# 14. Visualize the confusion matrix for Level 2 (optional)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(test_y_l2.cpu().numpy(), pred_l2)\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Level 2 Categories')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.savefig(os.path.join(embeddings_dir, 'l2_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f8aff",
   "metadata": {},
   "source": [
    "# Combine the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d79be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined architecture that integrates MasterGNN with the hierarchical classifier\n",
    "class CombinedHierarchicalModel(nn.Module):\n",
    "    def __init__(self, text_dim, cat_embedding_dim, hidden_dim, num_classes_l1, num_classes_l2,\n",
    "                 chunk_input_dim=384, doc_embedding_dim=64, master_embedding_dim=16):\n",
    "        super(CombinedHierarchicalModel, self).__init__()\n",
    "        \n",
    "        # Document hierarchy processing components\n",
    "        self.chunk_gnn = ChunkGNN(input_dim=chunk_input_dim, \n",
    "                                  hidden_dim=128, \n",
    "                                  output_dim=doc_embedding_dim)\n",
    "        \n",
    "        self.master_gnn = MasterGNN(input_dim=doc_embedding_dim, \n",
    "                                    hidden_dim=32, \n",
    "                                    output_dim=master_embedding_dim)\n",
    "        \n",
    "        # Category hierarchy processing\n",
    "        self.category_gnn = CategoryGNN(cat_node_features.shape[1], 32, cat_embedding_dim)\n",
    "        \n",
    "        # Fully connected layers for classification - combining text features,\n",
    "        # category embeddings, and the master document embedding\n",
    "        combined_dim = text_dim + cat_embedding_dim + master_embedding_dim\n",
    "        \n",
    "        # Shared layers\n",
    "        self.fc1 = nn.Linear(combined_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        \n",
    "        # Output heads for hierarchical classification\n",
    "        self.out_l1 = nn.Linear(hidden_dim // 2, num_classes_l1)\n",
    "        self.out_l2 = nn.Linear(hidden_dim // 2, num_classes_l2)\n",
    "        \n",
    "        # Store category node mappings\n",
    "        self.node_to_idx = node_to_idx\n",
    "        \n",
    "    def process_documents(self, grouped_embeddings):\n",
    "        \"\"\"Process document embeddings through the document GNN pipeline\"\"\"\n",
    "        return process_with_gnns(grouped_embeddings, self.chunk_gnn, self.master_gnn)\n",
    "    \n",
    "    def forward(self, text_embeddings, edge_index, node_features, raw_document_chunks=None, master_embedding=None):\n",
    "        \"\"\"\n",
    "        Forward pass that optionally processes raw document chunks or uses pre-computed master embedding\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: Base text embeddings for classification\n",
    "            edge_index: Category graph edge indices\n",
    "            node_features: Category graph node features\n",
    "            raw_document_chunks: Raw document chunks to process through GNN pipeline (optional)\n",
    "            master_embedding: Pre-computed master embedding (used if raw_document_chunks is None)\n",
    "        \"\"\"\n",
    "        # Get category embeddings from GNN\n",
    "        cat_embeddings = self.category_gnn(node_features, edge_index)\n",
    "        \n",
    "        # Process documents if provided, otherwise use the pre-computed master embedding\n",
    "        if raw_document_chunks is not None:\n",
    "            # Process documents through GNN pipeline\n",
    "            doc_master_embedding = self.process_documents(raw_document_chunks)\n",
    "        else:\n",
    "            # Use pre-computed master embedding if provided\n",
    "            doc_master_embedding = master_embedding\n",
    "            \n",
    "            # Ensure it's the right shape for batch processing\n",
    "            if len(doc_master_embedding.shape) == 1:\n",
    "                # If single embedding vector, reshape to batch size 1\n",
    "                doc_master_embedding = doc_master_embedding.unsqueeze(0)\n",
    "        \n",
    "        # For each text sample, combine with category embedding and document master embedding\n",
    "        batch_size = text_embeddings.shape[0]\n",
    "        combined_features = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # In a real implementation, we would use actual category info\n",
    "            # For now, we'll use a zero vector as a placeholder\n",
    "            dummy_cat_embedding = torch.zeros(cat_embeddings.shape[1], device=text_embeddings.device)\n",
    "            \n",
    "            # Determine which document embedding to use\n",
    "            if doc_master_embedding.shape[0] == 1:\n",
    "                # If only one document embedding, use it for all samples\n",
    "                doc_emb = doc_master_embedding.squeeze(0)\n",
    "            else:\n",
    "                # If we have batch-aligned document embeddings\n",
    "                doc_emb = doc_master_embedding[i]\n",
    "            \n",
    "            # Combine text embedding with category embedding and document master embedding\n",
    "            combined = torch.cat([\n",
    "                text_embeddings[i], \n",
    "                dummy_cat_embedding, \n",
    "                doc_emb\n",
    "            ])\n",
    "            combined_features.append(combined)\n",
    "        \n",
    "        combined_features = torch.stack(combined_features)\n",
    "        \n",
    "        # Shared layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "        # Output heads\n",
    "        out_l1 = self.out_l1(x)\n",
    "        out_l2 = self.out_l2(x)\n",
    "        \n",
    "        return out_l1, out_l2, cat_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd93e8",
   "metadata": {},
   "source": [
    "# train the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca633069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use the combined model\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the combined model\n",
    "    text_dim = train_embeddings.shape[1]\n",
    "    cat_embedding_dim = 64\n",
    "    hidden_dim = 256\n",
    "    \n",
    "    combined_model = CombinedHierarchicalModel(\n",
    "        text_dim=text_dim,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes_l1=num_classes_l1,\n",
    "        num_classes_l2=num_classes_l2,\n",
    "        chunk_input_dim=384,\n",
    "        doc_embedding_dim=64,\n",
    "        master_embedding_dim=16\n",
    "    ).to(device)\n",
    "    \n",
    "    # Set up optimizer for combined model\n",
    "    optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create master embeddings for each training sample (pre-compute once to save time)\n",
    "    print(\"Pre-computing document master embeddings...\")\n",
    "    \n",
    "    # This assumes you have raw document chunks for each training sample\n",
    "    # In a real scenario, you would need to map each training sample to its chunks\n",
    "    train_master_embeddings = []\n",
    "    \n",
    "    for i in range(len(train_x)):\n",
    "        # Get document chunks for this sample (simplified example)\n",
    "        # In reality, you would need to have a mapping from samples to documents\n",
    "        sample_documents = raw_document_chunks[i]  # This is just a placeholder\n",
    "        \n",
    "        # Process through document GNN pipeline\n",
    "        with torch.no_grad():\n",
    "            master_embedding = combined_model.process_documents(sample_documents)\n",
    "            train_master_embeddings.append(master_embedding)\n",
    "    \n",
    "    train_master_embeddings = torch.stack(train_master_embeddings).to(device)\n",
    "    \n",
    "    # Modified training function to use pre-computed master embeddings\n",
    "    def train_epoch(model, optimizer, batch_x, batch_y_l1, batch_y_l2, master_embeddings):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with pre-computed master embeddings\n",
    "        out_l1, out_l2, _ = model(\n",
    "            batch_x, cat_edge_index, cat_node_features,\n",
    "            master_embedding=master_embeddings\n",
    "        )\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_l1 = F.cross_entropy(out_l1, batch_y_l1)\n",
    "        loss_l2 = F.cross_entropy(out_l2, batch_y_l2)\n",
    "        total_loss = 0.4 * loss_l1 + 0.6 * loss_l2\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return total_loss.item(), loss_l1.item(), loss_l2.item()\n",
    "    \n",
    "    # Training loop with master embeddings\n",
    "    print(\"\\nTraining the combined hierarchical GNN model...\")\n",
    "    epochs = 200\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train on training data with master embeddings\n",
    "        total_loss, loss_l1, loss_l2 = train_epoch(\n",
    "            combined_model, optimizer, train_x, train_y_l1, train_y_l2, train_master_embeddings\n",
    "        )\n",
    "        \n",
    "        losses.append(total_loss)\n",
    "        \n",
    "        if (epoch + 1) % 15 == 0 or epoch == 0:\n",
    "            # Evaluate on validation data (would need val_master_embeddings)\n",
    "            # This is just a placeholder - you would compute val_master_embeddings similar to train\n",
    "            val_acc_l1, val_acc_l2, _, _ = evaluate_combined(\n",
    "                combined_model, val_x, val_y_l1, val_y_l2, val_master_embeddings\n",
    "            )\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, \"\n",
    "                  f\"Val Acc L1: {val_acc_l1:.4f}, L2: {val_acc_l2:.4f}\")\n",
    "            \n",
    "            # Update learning rate based on validation performance\n",
    "            scheduler.step(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516532ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
