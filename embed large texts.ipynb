{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68834b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index==0.9.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696a1fd",
   "metadata": {},
   "source": [
    "# hej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "# Step 1: Use LlamaIndex chunkers for better text splitting\n",
    "def split_text_with_sentence_splitter(text, chunk_size=512, chunk_overlap=50):\n",
    "    \"\"\"\n",
    "    Splits text using LlamaIndex SentenceSplitter which respects sentence boundaries.\n",
    "    This creates more natural, semantically coherent chunks than simple word-based splitting.\n",
    "    \"\"\"\n",
    "    # Create a Document object (LlamaIndex's container for text)\n",
    "    document = Document(text=text)\n",
    "    \n",
    "    # Create a SentenceSplitter - this splits by sentences and then combines them into chunks\n",
    "    sentence_splitter = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        paragraph_separator=\"\\n\\n\",  # Adjust as needed for your text\n",
    "        separator=\" \"                # Separator used when combining sentences\n",
    "    )\n",
    "    \n",
    "    # Parse the document into nodes\n",
    "    nodes = sentence_splitter.get_nodes_from_documents([document])\n",
    "    \n",
    "    # Extract text from each node\n",
    "    chunks = [node.text for node in nodes]\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i}: {chunk}\")  # Print first 50 characters of each chunk for debugging\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Step 2: Embed each chunk using SentenceTransformer\n",
    "class TextEmbedder:\n",
    "    def __init__(self, model_name=\"paraphrase-MiniLM-L6-v2\"):  # Using a more compatible model\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_text(self, chunks):\n",
    "        \"\"\"\n",
    "        Embeds a list of text chunks using SentenceTransformer.\n",
    "        \"\"\"\n",
    "        return self.model.encode(chunks)\n",
    "\n",
    "# Step 3: Group embeddings by text\n",
    "def process_texts(texts, chunk_size=20, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Processes multiple texts, splits them into chunks, embeds them, and groups embeddings by text.\n",
    "    \"\"\"\n",
    "    embedder = TextEmbedder()\n",
    "    grouped_embeddings = {}\n",
    "\n",
    "    for idx, text in enumerate(texts):\n",
    "        chunks = split_text_with_sentence_splitter(text, chunk_size, chunk_overlap)\n",
    "        if chunks:  # Make sure we have chunks before proceeding\n",
    "            embeddings = embedder.embed_text(chunks)\n",
    "            grouped_embeddings[f\"text_{idx}\"] = np.array(embeddings)\n",
    "\n",
    "    return grouped_embeddings\n",
    "\n",
    "# The rest of your GNN code remains the same\n",
    "# ...\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    texts = [\n",
    "        \"This is the first example text. It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks . It is quite long and needs to be split into chunks .\",\n",
    "        \"Here is another text that will also be split and embedded.Here is another text that will also be split and embedded.Here is another text that will also be split and embedded.Here is another text that will also be split and embedded.Here is another text that will also be split and embedded.\",\n",
    "         \"Here is another text that will also be split and embedded.Here is another text that will also be split and embedded.\"\n",
    "    ]\n",
    "\n",
    "    # Process texts with LlamaIndex chunker\n",
    "    grouped_embeddings = process_texts(texts)\n",
    "    \n",
    "    # Print information about the chunks\n",
    "    for text_id, embeddings in grouped_embeddings.items():\n",
    "        print(f\"{text_id}: {len(embeddings)} chunks with embedding dimension {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4536f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9538870",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_embedding.size(0)  # Replace 0 with the dimension you want to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# Step 1: Define the GNN models\n",
    "class ChunkGNN(nn.Module):\n",
    "    \"\"\"GNN for creating document-level embeddings from chunks\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ChunkGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = global_mean_pool(x, batch)  # Pooling to get document-level embedding\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MasterGNN(nn.Module):\n",
    "    \"\"\"Graph neural network for aggregating document embeddings into a fixed-size master embedding\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MasterGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, document_embeddings):\n",
    "        \"\"\"\n",
    "        Create a fixed-size master embedding from document embeddings using a graph approach\n",
    "        \n",
    "        Args:\n",
    "            document_embeddings: Tensor of shape [num_documents, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "            Fixed-size master embedding regardless of number of input documents\n",
    "        \"\"\"\n",
    "        # Create a single batch for all documents (all in one graph)\n",
    "        batch = torch.zeros(document_embeddings.size(0), dtype=torch.long)\n",
    "        \n",
    "        # Create a fully connected graph between documents\n",
    "        if document_embeddings.size(0) > 1:\n",
    "            # Generate all pairs of indices for a fully connected graph\n",
    "            edge_index = torch.combinations(torch.arange(document_embeddings.size(0)), r=2).t()\n",
    "            # Make edges bidirectional\n",
    "            edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        else:\n",
    "            # Self-loop for a single document\n",
    "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "        \n",
    "        # Process through GNN\n",
    "        x = self.conv1(document_embeddings, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Global pooling to get fixed-size representation regardless of document count\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Step 2: Prepare data for chunk-level GNN\n",
    "def prepare_chunk_data(grouped_embeddings):\n",
    "    \"\"\"Convert grouped embeddings into PyTorch Geometric Data objects\"\"\"\n",
    "    data_list = []\n",
    "    for text_id, embeddings in grouped_embeddings.items():\n",
    "        # Create node features\n",
    "        x = torch.tensor(embeddings, dtype=torch.float)\n",
    "        \n",
    "        # Create a fully connected graph between chunks\n",
    "        num_nodes = x.size(0)\n",
    "        if num_nodes > 1:\n",
    "            # Create bidirectional edges for better message passing\n",
    "            edge_index = torch.combinations(torch.arange(num_nodes), r=2).t()\n",
    "            edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        else:\n",
    "            # Handle single node case with self-loop\n",
    "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "            \n",
    "        # Create a Data object\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        data_list.append(data)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Step 3: Process grouped embeddings through the GNNs\n",
    "def process_with_gnns(grouped_embeddings, chunk_gnn, master_gnn):\n",
    "    \"\"\"Process embeddings through GNNs to get a single fixed-size master embedding\"\"\"\n",
    "    # Prepare chunk-level data\n",
    "    data_list = prepare_chunk_data(grouped_embeddings)\n",
    "    loader = DataLoader(data_list, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Process each document through chunk-level GNN\n",
    "    document_embeddings = []\n",
    "    for data in loader:\n",
    "        document_embedding = chunk_gnn(data.x, data.edge_index, data.batch)\n",
    "        document_embeddings.append(document_embedding.squeeze(0))  # Remove batch dimension\n",
    "    \n",
    "    # Stack document embeddings\n",
    "    document_embeddings = torch.stack(document_embeddings)\n",
    "    \n",
    "    # Process through master GNN to get fixed-size embedding\n",
    "    master_embedding = master_gnn(document_embeddings)\n",
    "    \n",
    "    return master_embedding\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # For testing with different numbers of documents\n",
    "    test_cases = [\n",
    "        {\"text_0\": np.random.rand(5, 384)},  # 1 document\n",
    "        {\"text_0\": np.random.rand(5, 384), \"text_1\": np.random.rand(3, 384)},  # 2 documents\n",
    "        {\"text_0\": np.random.rand(5, 384), \"text_1\": np.random.rand(3, 384), \n",
    "         \"text_2\": np.random.rand(4, 384), \"text_3\": np.random.rand(4, 384)}  # 4 documents\n",
    "    ]\n",
    "    \n",
    "    # Define fixed embedding dimensions\n",
    "    embedding_dim = 384\n",
    "    output_dim = 64\n",
    "    \n",
    "    # Initialize models\n",
    "    chunk_gnn = ChunkGNN(input_dim=embedding_dim, hidden_dim=128, output_dim=output_dim)\n",
    "    master_gnn = MasterGNN(input_dim=output_dim, hidden_dim=32, output_dim=16)\n",
    "    \n",
    "    # Test with different numbers of documents\n",
    "    for i, grouped_embeddings in enumerate(test_cases):\n",
    "        print(f\"\\nTest case {i+1}: {len(grouped_embeddings)} documents\")\n",
    "        \n",
    "        # Process embeddings\n",
    "        master_embedding = process_with_gnns(grouped_embeddings, chunk_gnn, master_gnn)\n",
    "        \n",
    "        # Verify shape is consistent\n",
    "        print(f\"Master embedding shape: {master_embedding.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
